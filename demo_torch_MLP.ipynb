{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO (6.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few hyperparameters.\n",
    "future_num = 3                      # Change it carefully because the order of futures also matters.\n",
    "choose_num = 33                       \n",
    "test_num = 10\n",
    "bootsrap_num = 20\n",
    "test_length = 100                   # The length of the test data\n",
    "batch_size = 250                      # Batch size is important when constructing the dataloader.\n",
    "hidden_size = 64                    # Neural network hyperparams\n",
    "learning_rate = 1e-3                                \n",
    "epochs = 5                          # Iterating times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集PR尺寸为:(362, 36)\n"
     ]
    }
   ],
   "source": [
    "# Load the prepared data.\n",
    "Price = pd.read_csv('./test_'+str(choose_num)+'/Dataset.csv', encoding='gbk')\n",
    "Rate_3m = pd.read_csv('./test_'+str(choose_num)+'/Rate_3m.csv', encoding='gbk')\n",
    "N = Rate_3m.shape[0]                                     \n",
    "# N days counted\n",
    "\n",
    "Price = Price.drop(Price.tail(1).index)\n",
    "# Same length(PRICE & RATE)\n",
    "\n",
    "# By considering the multiplier seperately, we can multiply Price by the 'variables' immediately.\n",
    "Price[['IF','IH']] = 300 * Price[['IF','IH']]\n",
    "Price[['IC']] = 200 * Price[['IC']]\n",
    "Price[Price.columns.difference(['Date','IF','IC','IH'])] = 100 * Price[Price.columns.difference(['Date','IF','IC','IH'])]\n",
    "\n",
    "# Transform data to np.array(dtype=float) and put 'date' away.\n",
    "Price_np = np.array((np.array(Price))[:,1:], dtype=float)\n",
    "Rate_3m_np = np.array((np.array(Rate_3m))[:,1:], dtype=float)\n",
    "\n",
    "# PR is all we need.\n",
    "PR = Price_np * Rate_3m_np\n",
    "# From the perspective of 'mlp_solve.py', PR = PR_F_bst '+' PR_E_bst\n",
    "# Thanks to the DataLoader from torch.utils.data, it could be easier to sample data with 'shuffle', as follows.\n",
    "print('数据集PR尺寸为:{}'.format(PR.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the training dataset and the test dataset.\n",
    "class hedge_data(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        super(hedge_data, self).__init__()\n",
    "        # 'data' is designded based on 'PR'. \n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(self.data[index])\n",
    "\n",
    "train_data = hedge_data(PR[:-test_length,:], transform=torch.tensor)    # test_length = the size of the test data\n",
    "test_data = hedge_data(PR[-test_length:,:], transform=torch.tensor)\n",
    "\n",
    "# Constructing dataloaders.\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, drop_last=True)   \n",
    "# Only shuffle the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Confirm our device first.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naivenn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(naivenn, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Here we can make some differences about the structure of the neural network.\n",
    "        # Try CNN, MLP...\n",
    "\n",
    "        self.naive_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.ReLU(),                         \n",
    "            # We try to make the output >= 0 by applying ReLU, but still can improve.\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        portfolio = self.naive_stack(x.to(torch.float))\n",
    "        # Split the portfolio to futures and etfs.\n",
    "        holding_f, holding_e = portfolio.split([future_num, portfolio.shape[1]-future_num], dim=1)  \n",
    "        return holding_f, holding_e                    # Output is the portfolio.\n",
    "\n",
    "# Now we can bulid our naive model!\n",
    "\n",
    "naive_model = naivenn(PR.shape[1], hidden_size, PR.shape[1])\n",
    "loss_f = nn.MSELoss()\n",
    "opt = torch.optim.SGD(naive_model.parameters(), lr = learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train:\n",
    "def trainloop(dataloader, model, loss_function, optimizer):\n",
    "    # Running trainloop once means that we 'bianli' or traverse the dataloader once.\n",
    "    for idx, x in enumerate(dataloader):\n",
    "        # Compute loss\n",
    "        hold_f, hold_e = model(x)\n",
    "        hold_f, hold_e = torch.tensor(hold_f, dtype=float), torch.tensor(hold_e, dtype=float)\n",
    "        # The above line will raise a warning, but we can ignore it.\n",
    "        # Mind the dtype.\n",
    "        # Split the PnL data.\n",
    "        pr_f, pr_e = x.split([future_num, hold_e.shape[1] + hold_f.shape[1] - future_num], dim=1) \n",
    "\n",
    "        error = -(hold_f @ pr_f.T - hold_e @ pr_e.T)              # PnL error               \n",
    "        loss = loss_function(error, torch.zeros_like(error))      # loss\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()            # Set the gradient as 0.\n",
    "        loss = loss.requires_grad_()\n",
    "        loss.backward()                  # Compute the gradient by BP algorithm.\n",
    "        optimizer.step()                 # Update the parameters with the given optimizer.\n",
    "\n",
    "# Test:\n",
    "def testloop(dataloader, model, loss_function):\n",
    "    # Running testloop once we will obtain a list of error rate, then we observe the quantile and minimum.\n",
    "    test_loss = []\n",
    "    # test_loss = list[abs(error_i) / cost_i]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, x in enumerate(dataloader):\n",
    "            hold_f, hold_e = model(x)\n",
    "            hold_f, hold_e = np.array(hold_f, dtype=float), np.array(hold_e, dtype=float)\n",
    "            idx_cost = len(train_data) + idx\n",
    "            cost_array = Price_np[idx_cost]\n",
    "            cost_f = cost_array[:future_num]\n",
    "            cost_e = cost_array[future_num:]\n",
    "            rate_array = Rate_3m_np[idx_cost]\n",
    "            rate_f = rate_array[:future_num]\n",
    "            rate_e = rate_array[future_num:]\n",
    "\n",
    "            hc_f, hc_e = hold_f * cost_f.T, hold_e * cost_e.T\n",
    "            # hc = hold * cost\n",
    "            # hc_f or hc_e may be zero!\n",
    "\n",
    "\n",
    "            # Before we compute the rate error, we should scale the hc_f and hc_e!\n",
    "            if np.sum(hc_f != 0) and np.sum(hc_e != 0):\n",
    "\n",
    "                hc_f = hc_f / np.sum(hc_f)    \n",
    "                hc_e = hc_e / np.sum(hc_e)\n",
    "\n",
    "                Rate_F = hc_f @ rate_f.T\n",
    "                Rate_E = hc_e @ rate_e.T\n",
    "                test_loss.append(Rate_E - Rate_F)\n",
    "    \n",
    "    test_loss_np = np.array(test_loss)\n",
    "    # print the min and the quantile.\n",
    "    print('test: min:{}, quantile:{}'.format(np.min(test_loss_np), np.percentile(test_loss_np, 5, interpolation='midpoint')))\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\123\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: min:-0.02444471391362239, quantile:-0.008711938767885567\n",
      "Epoch2\n",
      "-----------------------\n",
      "test: min:-0.02444471391362239, quantile:-0.008711938767885567\n",
      "Epoch3\n",
      "-----------------------\n",
      "test: min:-0.02444471391362239, quantile:-0.008711938767885567\n",
      "Epoch4\n",
      "-----------------------\n",
      "test: min:-0.02444471391362239, quantile:-0.008711938767885567\n",
      "Epoch5\n",
      "-----------------------\n",
      "test: min:-0.02444471391362239, quantile:-0.008711938767885567\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    print(f'Epoch{i+1}\\n-----------------------')\n",
    "    trainloop(train_dataloader, naive_model, loss_f, opt)\n",
    "    testloop(test_dataloader, naive_model, loss_f)\n",
    "    \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff7b88bac876f048267280bc8ebc4d6075519bb3d230ac42f46ed515902f8fdc"
  },
  "kernelspec": {
   "display_name": "Python 3.6.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
